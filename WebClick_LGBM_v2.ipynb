{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tiabet/DACON_WebClick/blob/main/WebClick_LGBM_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VRl5-bRPto7x"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XjCwG9lHt3hn"
      },
      "outputs": [],
      "source": [
        "train = pd.read_parquet('/content/drive/MyDrive/data/train_100000.parquet')\n",
        "test = pd.read_parquet('/content/drive/MyDrive/data/test_100000.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3Fqfu2q8uG6p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee250a5e-72a5-4838-b0ed-b68eb4bc0f90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "F01\n",
              "JCDXFYU    15636634\n",
              "LLKAVMO     6532633\n",
              "VNOHLIR     1455676\n",
              "XOZOJFY     1062708\n",
              "VFTOLQT      697032\n",
              "TVWQYKH      483327\n",
              "GLPZFND      464013\n",
              "UCFAVXY      372176\n",
              "VHLLSXG      353122\n",
              "CYOAMVC      338057\n",
              "PWUPWWR      331736\n",
              "QWAECUS      306916\n",
              "WDWZKGX      295626\n",
              "RVMYLQZ      275735\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "train['F01'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gZBOOxQHuwES",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc6dddc6-26c1-43e8-8594-4960d082bbf8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "F01\n",
              "JCDXFYU    2558134\n",
              "LLKAVMO     872775\n",
              "VNOHLIR     247349\n",
              "XOZOJFY     193681\n",
              "TVWQYKH     108813\n",
              "VFTOLQT      97665\n",
              "PWUPWWR      62062\n",
              "UCFAVXY      61935\n",
              "VHLLSXG      58178\n",
              "GLPZFND      57911\n",
              "QWAECUS      45844\n",
              "CYOAMVC      44617\n",
              "WDWZKGX      43936\n",
              "ZUHRSTZ      43823\n",
              "RVMYLQZ      41818\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "test['F01'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rRE-enomu_VX"
      },
      "outputs": [],
      "source": [
        "# 동일한 결과 보장을 위해 Seed값을 고정합니다\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "seed_everything(42) # Seed를 42로 고정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cK_MjZnsvuLw"
      },
      "outputs": [],
      "source": [
        "train = train.groupby('Click').apply(lambda x: x.sample(min(len(x), 5569860)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Fa7wL4ZpvHqv"
      },
      "outputs": [],
      "source": [
        "train_x = train.drop('Click', axis = 1)\n",
        "train_y = train['Click']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gxrqB8EM0FRF"
      },
      "outputs": [],
      "source": [
        "del train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gFm0eN6szzC7"
      },
      "outputs": [],
      "source": [
        "# Label encode categorical columns\n",
        "def label_encode_columns(train_df, test_df):\n",
        "    le = LabelEncoder()\n",
        "    for column in train_df.columns:\n",
        "        if train_df[column].dtype == 'object' or isinstance(train_df[column].dtype, pd.CategoricalDtype):\n",
        "            # Fit the LabelEncoder on the combined data to ensure consistency\n",
        "            combined_data = pd.concat([train_df[column], test_df[column]], axis=0).astype(str)\n",
        "            le.fit(combined_data)\n",
        "            train_df[column] = le.transform(train_df[column].astype(str))\n",
        "            test_df[column] = le.transform(test_df[column].astype(str))\n",
        "    return train_df, test_df\n",
        "\n",
        "# Apply label encoding to train_x and test_x\n",
        "train_x, test_x = label_encode_columns(train_x, test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTTCUkdcv9-M",
        "outputId": "4c1525c7-7300-43d3-b54a-ba264a08edff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(train_x)==len(train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "an-FT49jv-N_"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MLLHAt6wgFy"
      },
      "source": [
        "Optuna 하이퍼파라미터 튜닝"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSxfsPS5w_Az"
      },
      "source": [
        "LGBMClassifier(colsample_bytree=0.6829731847990743,\n",
        "               learning_rate=0.041926565437435385, max_bin=1023,\n",
        "               min_child_samples=14, n_estimators=6159, n_jobs=-1,\n",
        "               num_leaves=225, reg_alpha=0.00706357318094864,\n",
        "               reg_lambda=0.4980866507512539, verbose=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9IHtgBL_wCUZ"
      },
      "outputs": [],
      "source": [
        "# import optuna\n",
        "# import lightgbm as lgb\n",
        "# from lightgbm import early_stopping\n",
        "# from sklearn import metrics\n",
        "\n",
        "# def objective(trial):\n",
        "#     param = {\n",
        "#         'objective': 'binary',\n",
        "#         'verbosity': -1,\n",
        "#         'boosting_type': 'gbdt',\n",
        "#         'n_jobs':-1,\n",
        "#         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.9),\n",
        "#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
        "#         'max_bin': 1023,\n",
        "#         'min_child_samples': trial.suggest_int('min_child_samples', 5, 30),\n",
        "#         'n_estimators': trial.suggest_int('n_estimators', 3000, 8000),\n",
        "#         'num_leaves': trial.suggest_int('num_leaves', 100, 300),\n",
        "#         'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 0.1),\n",
        "#         'reg_lambda': trial.suggest_float('reg_lambda', 0.1, 1.0),\n",
        "#     }\n",
        "\n",
        "#     clf = lgb.LGBMClassifier(**param)\n",
        "#     # Include eval_set and early_stopping_rounds\n",
        "#     clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=[early_stopping(stopping_rounds=10)])\n",
        "#     preds = clf.predict_proba(X_val)[:, 1]\n",
        "#     auc = metrics.roc_auc_score(y_val, preds)\n",
        "#     return auc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "h9u4_f0Uw7fm"
      },
      "outputs": [],
      "source": [
        "# study = optuna.create_study(direction='maximize')\n",
        "# study.optimize(objective, n_trials=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbNcLFsPTd6D",
        "outputId": "5f6217ae-544e-4ca7-cd53-080325e61906"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flaml\n",
            "  Downloading FLAML-2.1.2-py3-none-any.whl (296 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/296.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.7/296.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: NumPy>=1.17 in /usr/local/lib/python3.10/dist-packages (from flaml) (1.25.2)\n",
            "Installing collected packages: flaml\n",
            "Successfully installed flaml-2.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install flaml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5srdEhzns4H7",
        "outputId": "05585911-3a9d-4076-b2fb-29542cd15b76"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.3.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uwwmOZnlTeSF"
      },
      "outputs": [],
      "source": [
        "from flaml import AutoML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YJWCP3wQTfh0"
      },
      "outputs": [],
      "source": [
        "# Initialize AutoML\n",
        "automl = AutoML()\n",
        "\n",
        "automl_settings = {\n",
        "    \"time_budget\": 10800,  # Total time budget in seconds\n",
        "    \"metric\": 'roc_auc',  # Evaluation metric\n",
        "    \"task\": 'classification',  # Task type\n",
        "    \"log_file_name\": 'automl.log',  # Log file\n",
        "    #\"estimator_list\": ['lgbm', 'xgboost', 'catboost', 'rf', 'extra_tree'],  # List of estimators to use\n",
        "     \"estimator_list\": ['lgbm'],\n",
        "    #\"eval_method\": \"holdout\",  # Use holdout validation method\n",
        "    # \"split_ratio\": 0.2,  # Ratio of data to be used as validation set\n",
        "    \"early_stop\": 10\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrOCqA1CVM4d",
        "outputId": "aa24ae69-d165-4e1d-9a19-80a54c249fea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 05-29 05:05:00] {1680} INFO - task = classification\n",
            "[flaml.automl.logger: 05-29 05:05:00] {1688} INFO - Data split method: stratified\n",
            "[flaml.automl.logger: 05-29 05:05:00] {1691} INFO - Evaluation method: holdout\n",
            "[flaml.automl.logger: 05-29 05:05:07] {1789} INFO - Minimizing error metric: 1-roc_auc\n",
            "[flaml.automl.logger: 05-29 05:05:07] {1901} INFO - List of ML learners in AutoML Run: ['lgbm']\n",
            "[flaml.automl.logger: 05-29 05:05:07] {2219} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:09] {2345} INFO - Estimated sufficient time budget=10891003s. Estimated necessary time budget=10891s.\n",
            "[flaml.automl.logger: 05-29 05:05:09] {2392} INFO -  at 90.7s,\testimator lgbm's best error=0.3827,\tbest estimator lgbm's best error=0.3827\n",
            "[flaml.automl.logger: 05-29 05:05:09] {2219} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:10] {2392} INFO -  at 91.8s,\testimator lgbm's best error=0.3827,\tbest estimator lgbm's best error=0.3827\n",
            "[flaml.automl.logger: 05-29 05:05:10] {2219} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:11] {2392} INFO -  at 92.9s,\testimator lgbm's best error=0.3739,\tbest estimator lgbm's best error=0.3739\n",
            "[flaml.automl.logger: 05-29 05:05:11] {2219} INFO - iteration 3, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:12] {2392} INFO -  at 94.3s,\testimator lgbm's best error=0.3339,\tbest estimator lgbm's best error=0.3339\n",
            "[flaml.automl.logger: 05-29 05:05:12] {2219} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:13] {2392} INFO -  at 95.4s,\testimator lgbm's best error=0.3339,\tbest estimator lgbm's best error=0.3339\n",
            "[flaml.automl.logger: 05-29 05:05:13] {2219} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:15] {2392} INFO -  at 96.8s,\testimator lgbm's best error=0.3339,\tbest estimator lgbm's best error=0.3339\n",
            "[flaml.automl.logger: 05-29 05:05:15] {2219} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:16] {2392} INFO -  at 98.1s,\testimator lgbm's best error=0.3339,\tbest estimator lgbm's best error=0.3339\n",
            "[flaml.automl.logger: 05-29 05:05:16] {2219} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:17] {2392} INFO -  at 99.3s,\testimator lgbm's best error=0.3339,\tbest estimator lgbm's best error=0.3339\n",
            "[flaml.automl.logger: 05-29 05:05:17] {2219} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:19] {2392} INFO -  at 100.9s,\testimator lgbm's best error=0.3297,\tbest estimator lgbm's best error=0.3297\n",
            "[flaml.automl.logger: 05-29 05:05:19] {2219} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:20] {2392} INFO -  at 102.3s,\testimator lgbm's best error=0.3297,\tbest estimator lgbm's best error=0.3297\n",
            "[flaml.automl.logger: 05-29 05:05:20] {2219} INFO - iteration 10, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:24] {2392} INFO -  at 106.2s,\testimator lgbm's best error=0.3297,\tbest estimator lgbm's best error=0.3297\n",
            "[flaml.automl.logger: 05-29 05:05:24] {2219} INFO - iteration 11, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:26] {2392} INFO -  at 108.0s,\testimator lgbm's best error=0.3297,\tbest estimator lgbm's best error=0.3297\n",
            "[flaml.automl.logger: 05-29 05:05:26] {2219} INFO - iteration 12, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:28] {2392} INFO -  at 109.8s,\testimator lgbm's best error=0.3137,\tbest estimator lgbm's best error=0.3137\n",
            "[flaml.automl.logger: 05-29 05:05:28] {2219} INFO - iteration 13, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:30] {2392} INFO -  at 111.8s,\testimator lgbm's best error=0.3137,\tbest estimator lgbm's best error=0.3137\n",
            "[flaml.automl.logger: 05-29 05:05:30] {2219} INFO - iteration 14, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:32] {2392} INFO -  at 113.7s,\testimator lgbm's best error=0.3105,\tbest estimator lgbm's best error=0.3105\n",
            "[flaml.automl.logger: 05-29 05:05:32] {2219} INFO - iteration 15, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:34] {2392} INFO -  at 115.6s,\testimator lgbm's best error=0.3105,\tbest estimator lgbm's best error=0.3105\n",
            "[flaml.automl.logger: 05-29 05:05:34] {2219} INFO - iteration 16, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:35] {2392} INFO -  at 117.3s,\testimator lgbm's best error=0.3105,\tbest estimator lgbm's best error=0.3105\n",
            "[flaml.automl.logger: 05-29 05:05:35] {2219} INFO - iteration 17, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:37] {2392} INFO -  at 119.1s,\testimator lgbm's best error=0.3105,\tbest estimator lgbm's best error=0.3105\n",
            "[flaml.automl.logger: 05-29 05:05:37] {2219} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:39] {2392} INFO -  at 121.0s,\testimator lgbm's best error=0.3105,\tbest estimator lgbm's best error=0.3105\n",
            "[flaml.automl.logger: 05-29 05:05:39] {2219} INFO - iteration 19, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:40] {2392} INFO -  at 122.5s,\testimator lgbm's best error=0.3105,\tbest estimator lgbm's best error=0.3105\n",
            "[flaml.automl.logger: 05-29 05:05:40] {2219} INFO - iteration 20, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:43] {2392} INFO -  at 124.8s,\testimator lgbm's best error=0.3051,\tbest estimator lgbm's best error=0.3051\n",
            "[flaml.automl.logger: 05-29 05:05:43] {2219} INFO - iteration 21, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:45] {2392} INFO -  at 127.3s,\testimator lgbm's best error=0.3023,\tbest estimator lgbm's best error=0.3023\n",
            "[flaml.automl.logger: 05-29 05:05:45] {2219} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:48] {2392} INFO -  at 130.4s,\testimator lgbm's best error=0.3023,\tbest estimator lgbm's best error=0.3023\n",
            "[flaml.automl.logger: 05-29 05:05:48] {2219} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:51] {2392} INFO -  at 132.9s,\testimator lgbm's best error=0.3023,\tbest estimator lgbm's best error=0.3023\n",
            "[flaml.automl.logger: 05-29 05:05:51] {2219} INFO - iteration 24, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:53] {2392} INFO -  at 135.2s,\testimator lgbm's best error=0.3023,\tbest estimator lgbm's best error=0.3023\n",
            "[flaml.automl.logger: 05-29 05:05:53] {2219} INFO - iteration 25, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:56] {2392} INFO -  at 137.8s,\testimator lgbm's best error=0.2991,\tbest estimator lgbm's best error=0.2991\n",
            "[flaml.automl.logger: 05-29 05:05:56] {2219} INFO - iteration 26, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:05:58] {2392} INFO -  at 140.4s,\testimator lgbm's best error=0.2991,\tbest estimator lgbm's best error=0.2991\n",
            "[flaml.automl.logger: 05-29 05:05:58] {2219} INFO - iteration 27, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:06:03] {2392} INFO -  at 145.3s,\testimator lgbm's best error=0.2991,\tbest estimator lgbm's best error=0.2991\n",
            "[flaml.automl.logger: 05-29 05:06:03] {2219} INFO - iteration 28, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:06:05] {2392} INFO -  at 147.2s,\testimator lgbm's best error=0.2991,\tbest estimator lgbm's best error=0.2991\n",
            "[flaml.automl.logger: 05-29 05:06:05] {2219} INFO - iteration 29, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:06:07] {2392} INFO -  at 149.1s,\testimator lgbm's best error=0.2991,\tbest estimator lgbm's best error=0.2991\n",
            "[flaml.automl.logger: 05-29 05:06:07] {2219} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:06:11] {2392} INFO -  at 152.8s,\testimator lgbm's best error=0.2953,\tbest estimator lgbm's best error=0.2953\n",
            "[flaml.automl.logger: 05-29 05:06:11] {2219} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:06:15] {2392} INFO -  at 157.2s,\testimator lgbm's best error=0.2953,\tbest estimator lgbm's best error=0.2953\n",
            "[flaml.automl.logger: 05-29 05:06:15] {2219} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:06:20] {2392} INFO -  at 162.4s,\testimator lgbm's best error=0.2934,\tbest estimator lgbm's best error=0.2934\n",
            "[flaml.automl.logger: 05-29 05:06:20] {2219} INFO - iteration 33, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:06:25] {2392} INFO -  at 167.1s,\testimator lgbm's best error=0.2934,\tbest estimator lgbm's best error=0.2934\n",
            "[flaml.automl.logger: 05-29 05:06:25] {2219} INFO - iteration 34, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:06:32] {2392} INFO -  at 174.4s,\testimator lgbm's best error=0.2934,\tbest estimator lgbm's best error=0.2934\n",
            "[flaml.automl.logger: 05-29 05:06:32] {2219} INFO - iteration 35, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:06:49] {2392} INFO -  at 191.4s,\testimator lgbm's best error=0.2902,\tbest estimator lgbm's best error=0.2902\n",
            "[flaml.automl.logger: 05-29 05:06:49] {2219} INFO - iteration 36, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:06:55] {2392} INFO -  at 197.1s,\testimator lgbm's best error=0.2902,\tbest estimator lgbm's best error=0.2902\n",
            "[flaml.automl.logger: 05-29 05:06:55] {2219} INFO - iteration 37, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:07:31] {2392} INFO -  at 232.8s,\testimator lgbm's best error=0.2875,\tbest estimator lgbm's best error=0.2875\n",
            "[flaml.automl.logger: 05-29 05:07:31] {2219} INFO - iteration 38, current learner lgbm\n",
            "[flaml.automl.logger: 05-29 05:09:30] {2392} INFO -  at 352.4s,\testimator lgbm's best error=0.2875,\tbest estimator lgbm's best error=0.2875\n",
            "[flaml.automl.logger: 05-29 05:09:30] {2219} INFO - iteration 39, current learner lgbm\n"
          ]
        }
      ],
      "source": [
        "# Fit the model\n",
        "automl.fit(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, **automl_settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ppjODxUVPYN"
      },
      "outputs": [],
      "source": [
        "sample_submission = pd.read_csv('drive/MyDrive/data/sample_submission.csv')\n",
        "\n",
        "# Predict probabilities on the test set\n",
        "y_pred_test_proba = automl.predict_proba(test_x)[:, 1]\n",
        "\n",
        "# Output the probabilities for test set\n",
        "print(y_pred_test_proba)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVX1ul50VbEs"
      },
      "outputs": [],
      "source": [
        "sample_submission['Click'] = y_pred_test_proba\n",
        "sample_submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnHlWdDMVbR9"
      },
      "outputs": [],
      "source": [
        "sample_submission.to_csv(\"drive/MyDrive/data/automl_lgbm_prediction_v2.csv\",index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQqGeJjJVz0a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "mount_file_id": "1l6CpHgu4QAODpybn64R3yF7IS6JpjeMJ",
      "authorship_tag": "ABX9TyN7jgtbmrN/i4adKjJ34sgy",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}